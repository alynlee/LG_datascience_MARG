{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "day4_final_project_template.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN4mBkEwWJMMDpmNHaR+jbe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juheo/LG_datascience_MARG/blob/master/day4_final_project_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5XW_BCbBLYQ",
        "colab_type": "text"
      },
      "source": [
        "# FINAL PROJECT TEMPLATE\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XysrvWdjGeoQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train data (numpy ver) download\n",
        "!wget --no-check-certificate -qq -r 'https://docs.google.com/uc?export=download&id=1CFKZf97pTozo2DNPnDsMcY0SVPvN8mj-' -O recordings_npy.zip\n",
        "!mkdir speech_mnist\n",
        "!unzip -qq /content/recordings_npy.zip -d ./speech_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6yDXSWVBRq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import numpy as np \n",
        "import librosa\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential, Model, Input, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, Conv1D, BatchNormalization,pooling\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "# baseline model \n",
        "\n",
        "def pad(mel, max_length):\n",
        "  if np.shape(mel)[1] >= max_length:\n",
        "    return mel[:,:max_length]\n",
        "  else :\n",
        "    pad_length = max_length-np.shape(mel)[1]\n",
        "    return np.concatenate((mel, np.zeros((128, pad_length))), axis=1)\n",
        "\n",
        "\n",
        "def preprocessing(wav_path):\n",
        "  X_temp = []\n",
        "  Y = []\n",
        "  sr = 8000\n",
        "  n_fft = 512\n",
        "  hop_length = 128\n",
        "  classes = 10\n",
        "  for item in wav_path:\n",
        "    audio = np.load(item)\n",
        "    melspectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length =hop_length)\n",
        "    mel_norm = melspectrogram/np.max(melspectrogram)\n",
        "    mel_log = np.log(mel_norm+1e-5)\n",
        "    X_temp.append(melspectrogram)\n",
        "    label = np.eye(classes)[(int)(item.split('/')[-1].split('_')[0])]\n",
        "    Y.append(label)\n",
        "  \n",
        "  all_length = [] \n",
        "  for item in X_temp:\n",
        "    all_length.append(np.shape(item)[1])\n",
        "  max_length = np.max(all_length)\n",
        "\n",
        "  X = []\n",
        "  for item in X_temp:\n",
        "    X.append(pad(item, max_length))\n",
        "\n",
        "  X = np.asarray(X)\n",
        "  Y = np.asarray(Y)\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "\n",
        "def preprocessing_test(wav_path):\n",
        "  X_temp = []\n",
        "  Y = []\n",
        "  sr = 8000\n",
        "  n_fft = 512\n",
        "  hop_length = 128\n",
        "  classes = 10\n",
        "  for item in wav_path:\n",
        "    audio, sr = librosa.load(item, sr=sr)\n",
        "    melspectrogram = librosa.feature.melspectrogram(y=audio, sr=sr, n_fft=n_fft, hop_length =hop_length)\n",
        "    mel_norm = melspectrogram/np.max(melspectrogram)\n",
        "    mel_log = np.log(mel_norm+1e-5)\n",
        "    X_temp.append(melspectrogram)\n",
        "    label = np.eye(classes)[(int)(item.split('/')[-1].split('_')[0])]\n",
        "    Y.append(label)\n",
        "  \n",
        "  all_length = [] \n",
        "  for item in X_temp:\n",
        "    all_length.append(np.shape(item)[1])\n",
        "  max_length = np.max(all_length)\n",
        "\n",
        "  X = []\n",
        "  for item in X_temp:\n",
        "    X.append(pad(item, max_length))\n",
        "\n",
        "  X = np.asarray(X)\n",
        "  Y = np.asarray(Y)\n",
        "  return X, Y\n",
        "\n",
        "\n",
        "def build_model():\n",
        "  model = Sequential()\n",
        "  model.add(BatchNormalization(input_shape=(128,143)))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv1D(64,3,padding='same',kernel_initializer='he_normal'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Conv1D(64,3,padding='same',kernel_initializer='he_normal'))\n",
        "  model.add(pooling.MaxPooling1D(pool_size=2))\n",
        "  model.add(pooling.MaxPooling1D(pool_size=2))\n",
        "  model.add(pooling.AveragePooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(32, activation='relu'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  return model\n",
        "\n",
        "\n",
        "def train(model, X, Y):\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=777)\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "  hist = model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=0, validation_split=0.1)\n",
        "  return hist\n",
        "\n",
        "\n",
        "def evaluate(model, X, Y):\n",
        "  print(model.evaluate(X, Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HxlKRX7fMYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train data download\n",
        "!wget --no-check-certificate -qq -r 'https://docs.google.com/uc?export=download&id=1Rz0x4BqPDO6HgnuZMpkSYOFeYPWWZjav' -O recordings.zip\n",
        "!mkdir speech_mnist_test\n",
        "!unzip -qq /content/recordings.zip -d ./speech_mnist_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvvun90TGg_W",
        "colab_type": "code",
        "outputId": "a6b71f3c-2ad2-4bbd-f8d4-ac99c7b2af45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# evaluate\n",
        "\n",
        "wav_path = sorted(glob.glob('./speech_mnist/*.npy'))\n",
        "test_path = glob.glob('/content/speech_mnist_test/audio_test_two/*.wav')\n",
        "X, Y = preprocessing(wav_path)\n",
        "X_test, Y_test = preprocessing_test(test_path)\n",
        "print(np.shape(X))\n",
        "print(np.shape(X_test))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2000, 128, 143)\n",
            "(20, 128, 70)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD2bPosqfv7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_final = np.concatenate((X_test, np.zeros((20,128,73))),axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-eHvLbDfoJQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0d1f4c2a-4cdc-40b7-9e06-71d2378c5e16"
      },
      "source": [
        "model = build_model()\n",
        "hist = train(model, X, Y)\n",
        "evaluate(model, X_test_final, Y_test)\n",
        "\n",
        "\n",
        "\n",
        "''' 조교 최종 평가 코드 ''' \n",
        "\n",
        "final_test_path = glob.glob('/final_test/*.wav') # (8000Hz, 다양한 길이의 오디오 파일)\n",
        "X_test, Y_test = preprocessing_test(final_test_path)\n",
        "evaluate(model, X_test, Y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r20/20 [==============================] - 0s 475us/step\n",
            "[8.311784744262695, 0.3499999940395355]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}